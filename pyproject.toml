[tool.poetry]
name = "fast-perceiver"
version = "0.1.5"
description = ""
authors = ["Kristian Klemon <kristian.klemon@gmail.com>"]
readme = "README.md"
packages = [{include = "fast_perceiver"}]

[tool.poetry.dependencies]
python = "^3.10"
torch = {version = "^2.0.1", source = "pytorch-gpu-src"}
torchvision = {version = "^0.15.2", source = "pytorch-gpu-src"}
einops = "^0.6.1"
# FlashAttention has recently dropped PEP 5017 support since it led to issue with
#  declaring torch as dependency.
# Until this is resolved, we can't declare flash-attn as dependency and the user
#  needs to install it manually.
# See https://github.com/Dao-AILab/flash-attention/pull/193
# flash-attn = "^2.2.5"

[[tool.poetry.source]]
name = "pytorch-gpu-src"
url = "https://download.pytorch.org/whl/cu118"
priority = "explicit"


[tool.poetry.group.dev.dependencies]
tqdm = "^4.65.0"
pandas = "^2.0.3"
seaborn = "^0.12.2"
jupyter = "^1.0.0"
perceiver-pytorch = "^0.8.7"
pytest = "^7.4.0"
pytorch-lamb = {git = "https://github.com/cybertronai/pytorch-lamb.git"}

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
